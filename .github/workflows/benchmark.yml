name: Model Benchmarks

on:
  workflow_dispatch:
    inputs:
      models:
        description: 'Models to benchmark (comma-separated)'
        required: false
        default: 'qwen2.5:0.5b,qwen2.5:3b'
      tasks:
        description: 'Tasks to run (comma-separated)'
        required: false
        default: 'routing,code,math'
  schedule:
    # Run weekly on Sunday at midnight
    - cron: '0 0 * * 0'

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: self-hosted  # Requires self-hosted runner with GPU
    timeout-minutes: 120

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Check Ollama
        run: |
          curl -s http://localhost:11434/api/tags | jq '.models[].name'

      - name: Run benchmarks
        run: |
          mkdir -p benchmark_results
          python -m tinyllm.benchmark \
            --models "${{ github.event.inputs.models || 'qwen2.5:0.5b,qwen2.5:3b' }}" \
            --tasks "${{ github.event.inputs.tasks || 'routing,code,math' }}" \
            --output benchmark_results/results.json

      - name: Generate report
        run: |
          python -m tinyllm.benchmark.report \
            --input benchmark_results/results.json \
            --output benchmark_results/report.md

      - name: Get hardware info
        run: |
          echo "## Hardware Configuration" > benchmark_results/hardware.md
          echo "" >> benchmark_results/hardware.md
          echo "- **CPU**: $(lscpu | grep 'Model name' | cut -d':' -f2 | xargs)" >> benchmark_results/hardware.md
          echo "- **RAM**: $(free -h | grep Mem | awk '{print $2}')" >> benchmark_results/hardware.md
          echo "- **GPU**: $(nvidia-smi --query-gpu=name --format=csv,noheader 2>/dev/null | head -1 || echo 'N/A')" >> benchmark_results/hardware.md
          echo "- **VRAM**: $(nvidia-smi --query-gpu=memory.total --format=csv,noheader 2>/dev/null | head -1 || echo 'N/A')" >> benchmark_results/hardware.md
          cat benchmark_results/hardware.md

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.run_number }}
          path: benchmark_results/

      - name: Post results to PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('benchmark_results/report.md', 'utf8');
            const hardware = fs.readFileSync('benchmark_results/hardware.md', 'utf8');

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: `## Benchmark Results\n\n${hardware}\n\n${report}`
            });
